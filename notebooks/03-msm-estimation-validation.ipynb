{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSM estimation and validation\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons Licence\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" title='This work is licensed under a Creative Commons Attribution 4.0 International License.' align=\"right\"/></a>\n",
    "\n",
    "In this notebook, we will cover how to estimate a Markov state model (MSM) and do model validation;\n",
    "we also show how to save and restore model and estimator objects.\n",
    "For this notebook, you need to know how to do data loading/visualization as well as dimension reduction.\n",
    "\n",
    "\n",
    "**Remember**:\n",
    "- to run the currently highlighted cell, hold <kbd>&#x21E7; Shift</kbd> and press <kbd>&#x23ce; Enter</kbd>;\n",
    "- to get help for a specific function, place the cursor within the function's brackets, hold <kbd>&#x21E7; Shift</kbd>, and press <kbd>&#x21E5; Tab</kbd>;\n",
    "- you can find the full documentation for PyEMMA at [PyEMMA.org](http://www.pyemma.org) and for deeptime at [deeptime-ml.github.io](https://deeptime-ml.github.io/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import mdshare\n",
    "import pyemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading MD data and repeating the clustering step\n",
    "\n",
    "Let's load alanine dipeptide backbone torsions and discretise with 200 $k$-means centers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb = mdshare.fetch('alanine-dipeptide-nowater.pdb', working_directory='data')\n",
    "files = mdshare.fetch('alanine-dipeptide-*-250ns-nowater.xtc', working_directory='data')\n",
    "\n",
    "feat = pyemma.coordinates.featurizer(pdb)\n",
    "feat.add_backbone_torsions(periodic=False)\n",
    "\n",
    "data = pyemma.coordinates.load(files, features=feat)\n",
    "\n",
    "from deeptime.clustering import KMeans\n",
    "cluster = KMeans(200, max_iter=50, progress=tqdm)\\\n",
    "    .fit_fetch(np.concatenate(data)[::10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and plot the free energy along with the cluster centers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "pyemma.plots.plot_free_energy(*np.concatenate(data).T, ax=ax, legacy=False)\n",
    "ax.scatter(*cluster.cluster_centers.T, s=15, c='k')\n",
    "ax.set_xlabel('$\\Phi$ / rad') \n",
    "ax.set_ylabel('$\\Psi$ / rad')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implied time scales and lag time selection\n",
    "\n",
    "The first step after obtaining the discretized dynamics is finding a suitable lag time.\n",
    "The systematic approach is to estimate MSMs at various lag times and observe how the implied timescales (ITSs) of these models behave.\n",
    "In particular, we are looking for lag time ranges in which the implied timescales are constant.\n",
    "\n",
    "To that end we iterate over a range of lagtimes and estimate a Markov state model for each of them, subsequently computing the four slowest (``k=4``) timescales from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeptime.markov import TransitionCountEstimator\n",
    "from deeptime.markov.msm import MaximumLikelihoodMSM\n",
    "\n",
    "dtrajs = [cluster.transform(traj) for traj in data]\n",
    "\n",
    "lags = [1, 2, 5, 10, 20, 50]\n",
    "models = []\n",
    "for lag in tqdm(lags, leave=False):\n",
    "    counts_estimator = TransitionCountEstimator(lag, \"sliding\")\n",
    "    counts = counts_estimator.fit_fetch(dtrajs)\n",
    "    counts = counts.submodel_largest()\n",
    "    \n",
    "    msm_estimator = MaximumLikelihoodMSM()\n",
    "    models.append(msm_estimator.fit_fetch(counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{eqnarray*}\n",
    "T(n \\tau) & = & (T(\\tau))^n\\\\[0.75em]\n",
    "\\lambda(n \\tau) & = & (\\lambda(\\tau))^n\\\\[0.75em]\n",
    "\\mathrm{ITS}(n \\tau) & = & - \\frac{n \\tau}{\\ln \\lambda(n \\tau)} = - \\frac{n \\tau}{\\ln (\\lambda(\\tau))^n} = - \\frac{\\tau}{\\ln \\lambda(\\tau)} = \\mathrm{ITS}(\\tau)\n",
    "\\end{eqnarray*}$$\n",
    "\n",
    "We can pass the returned estimated timescales as \"lagtime-timescale\"-tuple to the `pyemma.plots.plot_implied_timescales()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeptime.util.validation import implied_timescales\n",
    "from deeptime.plots import plot_implied_timescales\n",
    "\n",
    "its = implied_timescales(models)\n",
    "ax = plot_implied_timescales(its, n_its=4)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('lagtime (ps)')\n",
    "ax.set_ylabel('timescales (ps)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot tells us that there are three resolved processes (blue, orange, green) which are largely invariant to the MSM lag time.\n",
    "The fourth ITS (red) is smaller than the lag time (black line, grey-shaded area);\n",
    "it corresponds to a process which is faster than the lag time and, thus, is not resolved.\n",
    "Since the implied timescales are, like the corresponding eigenvalues, sorted in decreasing order,\n",
    "we know that all other remaining processes must be even faster.\n",
    "\n",
    "## Error bars for the timescales\n",
    "\n",
    "Error bars can be obtained with Bayesian sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeptime.markov.msm import BayesianMSM\n",
    "\n",
    "def its_bayesian_msm(data, lagtimes):\n",
    "    models = []\n",
    "    for lagtime in tqdm(lagtimes):\n",
    "        counts = TransitionCountEstimator(lagtime, \"effective\").fit_fetch(data).submodel_largest()\n",
    "        models.append(BayesianMSM(n_samples=50).fit_fetch(counts))\n",
    "\n",
    "    return implied_timescales(models)\n",
    "\n",
    "its = its_bayesian_msm(dtrajs, [1, 2, 5, 10, 20, 50])\n",
    "\n",
    "ax = plot_implied_timescales(its, n_its=4)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('lagtime (ps)')\n",
    "ax.set_ylabel('timescales (ps)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of the discretization on the implied timescales\n",
    "\n",
    "Let's look at the discretisation's influence on the ITSs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def its_msm(data, lagtimes):\n",
    "    models = []\n",
    "    for lag in tqdm(lagtimes, leave=False):\n",
    "        counts = TransitionCountEstimator(lag, \"sliding\").fit_fetch(data).submodel_largest()\n",
    "        models.append(MaximumLikelihoodMSM().fit_fetch(counts))\n",
    "    return implied_timescales(models)\n",
    "\n",
    "lags = [1, 2, 5, 10, 20, 50]\n",
    "\n",
    "cluster_20 = KMeans(20, max_iter=50).fit_fetch(np.concatenate(data)[::10])\n",
    "its_20 = its_msm([cluster_20.transform(x) for x in data], lags)\n",
    "\n",
    "cluster_50 = KMeans(50, max_iter=50).fit_fetch(np.concatenate(data)[::10])\n",
    "its_50 = its_msm([cluster_50.transform(x) for x in data], lags)\n",
    "\n",
    "cluster_100 = KMeans(100, max_iter=50).fit_fetch(np.concatenate(data)[::10])\n",
    "its_100 = its_msm([cluster_100.transform(x) for x in data], lags);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(12, 6))\n",
    "\n",
    "pyemma.plots.plot_free_energy(*np.concatenate(data).T, ax=axes[0, 0], cbar=False)\n",
    "axes[0, 0].scatter(*cluster_20.cluster_centers.T, s=15, c='k')\n",
    "ax_its = plot_implied_timescales(its_20, ax=axes[1, 0], n_its=4)\n",
    "ax_its.set_yscale('log')\n",
    "ax_its.set_xlabel('lagtime (ps)')\n",
    "\n",
    "pyemma.plots.plot_free_energy(*np.concatenate(data).T, ax=axes[0, 1], cbar=False)\n",
    "axes[0, 1].scatter(*cluster_50.cluster_centers.T, s=15, c='k')\n",
    "ax_its = plot_implied_timescales(its_50, ax=axes[1, 1], n_its=4)\n",
    "ax_its.set_yscale('log')\n",
    "ax_its.set_xlabel('lagtime (ps)')\n",
    "\n",
    "pyemma.plots.plot_free_energy(*np.concatenate(data).T, ax=axes[0, 2], cbar=False)\n",
    "axes[0, 2].scatter(*cluster_100.cluster_centers.T, s=15, c='k')\n",
    "ax_its = plot_implied_timescales(its_100, ax=axes[1, 2], n_its=4)\n",
    "ax_its.set_yscale('log')\n",
    "ax_its.set_xlabel('lagtime (ps)')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the maximum likelihood Markov model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_estimator = TransitionCountEstimator(lagtime=10, count_mode='sliding')\n",
    "counts = counts_estimator.fit_fetch(dtrajs).submodel_largest()\n",
    "\n",
    "msm_estimator = MaximumLikelihoodMSM()\n",
    "msm = msm_estimator.fit_fetch(counts)\n",
    "\n",
    "print(f'fraction of states used = {msm.state_fraction}')\n",
    "print(f'fraction of counts used = {msm.count_fraction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msm.timescales(k=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The state space can be restricted to largest connected set (`submodel_largest()`) or any other selection of states:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = counts.submodel([0, 1, 3, 7])\n",
    "print(f\"States: {counts.states}, state symbols: {counts.state_symbols}\")\n",
    "msm = MaximumLikelihoodMSM().fit_fetch(counts)\n",
    "\n",
    "print(f'fraction of states used = {msm.state_fraction}')\n",
    "print(f'fraction of counts used = {msm.count_fraction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And restricted even further, always based on the _states_ of the current count model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = counts.submodel([0, 3])\n",
    "print(f\"States: {counts.states}, state symbols: {counts.state_symbols}\")\n",
    "msm = MaximumLikelihoodMSM().fit(counts).fetch_model()\n",
    "\n",
    "print(f'fraction of states used = {msm.state_fraction}')\n",
    "print(f'fraction of counts used = {msm.count_fraction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the Bayesian Markov model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_estimator = TransitionCountEstimator(lagtime=10, count_mode='effective')\n",
    "counts = count_estimator.fit_fetch(dtrajs).submodel_largest()\n",
    "bayesian_msm_estimator = BayesianMSM()\n",
    "bayesian_msm = bayesian_msm_estimator.fit_fetch(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = bayesian_msm.gather_stats('timescales', k=3)\n",
    "stats.L, stats.R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Chapman-Kolmogorov test\n",
    "\n",
    "To see whether our model satisfies Markovianity, we perform (and visualize) a Chapman-Kolmogorow (CK) test.\n",
    "Since we aim at modeling the dynamics between metastable states rather than between microstates, this will be conducted in the space of metastable states.\n",
    "The latter are identified automatically using PCCA++ (which is explained later).\n",
    "We usually choose the number of metastable states according to the implied timescales plot by identifying a gap between the ITS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = MaximumLikelihoodMSM(lagtime=10).fit_fetch(dtrajs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for lagtime in [10, 20, 30, 40, 50, 80, 100]:\n",
    "    models.append(MaximumLikelihoodMSM(lagtime=lagtime).fit_fetch(dtrajs))\n",
    "ck_test = test_model.ck_test(models, n_metastable_sets=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeptime.plots import plot_ck_test\n",
    "\n",
    "plot_ck_test(ck_test, xlabel='lagtime (ps)', sharey=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = TransitionCountEstimator(lagtime=10, count_mode='effective')\\\n",
    "    .fit_fetch(dtrajs).submodel_largest()\n",
    "test_bmsm = BayesianMSM().fit_fetch(counts)\n",
    "\n",
    "models = []\n",
    "for lagtime in tqdm([10, 20, 30, 40, 50, 80, 100]):\n",
    "    counts = TransitionCountEstimator(lagtime=lagtime, count_mode='effective')\\\n",
    "        .fit_fetch(dtrajs).submodel_largest()\n",
    "    models.append(BayesianMSM().fit_fetch(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_test = test_bmsm.ck_test(models, n_metastable_sets=4)\n",
    "plot_ck_test(ck_test, xlabel='lagtime (ps)', sharey=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persisting and restoring estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('cluster_50.pkl', 'wb') as f:\n",
    "    pickle.dump(cluster_50, f)\n",
    "    \n",
    "with open('cluster_50.pkl', 'rb') as f:\n",
    "    cluster_50_restored = pickle.load(f)\n",
    "    \n",
    "print(cluster_50_restored.n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('msm.pkl', 'wb') as f:\n",
    "    pickle.dump(msm, f)\n",
    "with open('msm.pkl', 'rb') as f:\n",
    "    msm_restored = pickle.load(f)\n",
    "    \n",
    "print(f\"Timescales {msm.timescales()}, restored {msm_restored.timescales()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-on\n",
    "\n",
    "#### Exercise 1\n",
    "\n",
    "Load the heavy atom distances into memory, perform PCA and TICA (`lag=3`) with `dim=2`,\n",
    "then discretize with $100$ $k$-means centers and a stride of $10$. Compare the two discretizations be generating implied timescale plots for both of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "feat =  #FIXME\n",
    "feat. #FIXME\n",
    "data =  #FIXME\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2).fit(np.concatenate(data))\n",
    "tica = #FIXME\n",
    "\n",
    "pca_output = #FIXME\n",
    "tica_output = [tica.transform(traj) for traj in data]\n",
    "\n",
    "cls_pca_estimator = KMeans(100, max_iter=50)\n",
    "cls_pca = #FIXME\n",
    "cls_tica = #FIXME\n",
    "\n",
    "dtrajs_pca = [cls_pca.transform(pca.transform(traj)) for traj in data]\n",
    "dtrajs_tica = # FIXME\n",
    "\n",
    "its_pca = implied_timescales_msm(dtrajs_pca, lags=[1, 2, 5, 10, 20, 50])\n",
    "its_tica = #FIXME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "###### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "feat = pyemma.coordinates.featurizer(pdb)\n",
    "pairs = feat.pairs(feat.select_Heavy())\n",
    "feat.add_distances(pairs, periodic=False)\n",
    "data = pyemma.coordinates.load(files, features=feat)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2).fit(np.concatenate(data))\n",
    "\n",
    "from deeptime.decomposition import TICA\n",
    "tica_estimator = TICA(lagtime=3, dim=2)\n",
    "tica = tica_estimator.fit_fetch(data)\n",
    "\n",
    "pca_output = [pca.transform(traj) for traj in data]\n",
    "tica_output = [tica.transform(traj) for traj in data]\n",
    "\n",
    "cls_pca = KMeans(100, max_iter=50).fit(np.concatenate(pca_output)[::10]).fetch_model()\n",
    "cls_tica = KMeans(100, max_iter=50).fit(np.concatenate(tica_output)[::10]).fetch_model()\n",
    "\n",
    "dtrajs_pca = [cls_pca.transform(pca.transform(traj)) for traj in data]\n",
    "dtrajs_tica = [cls_tica.transform(tica.transform(traj)) for traj in data]\n",
    "\n",
    "lags = [1, 2, 5, 10, 20, 50]\n",
    "its_pca = implied_timescales([MaximumLikelihoodMSM(lagtime=lag).fit_fetch(dtrajs_pca) for lag in lags])\n",
    "its_tica = implied_timescales([MaximumLikelihoodMSM(lagtime=lag).fit_fetch(dtrajs_tica) for lag in lags])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the ITS convergence for both projections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(12, 6))\n",
    "pyemma.plots.plot_feature_histograms(np.concatenate(pca_output), ax=axes[0, 0])\n",
    "pyemma.plots.plot_feature_histograms(np.concatenate(tica_output), ax=axes[1, 0])\n",
    "axes[0, 0].set_title('PCA')\n",
    "axes[1, 0].set_title('TICA')\n",
    "pyemma.plots.plot_density(*np.concatenate(pca_output).T, ax=axes[0, 1], cbar=False, alpha=0.1)\n",
    "axes[0, 1].scatter(*cls_pca.cluster_centers.T, s=15, c='C1')\n",
    "axes[0, 1].set_xlabel('PC 1')\n",
    "axes[0, 1].set_ylabel('PC 2')\n",
    "pyemma.plots.plot_density(*np.concatenate(tica_output).T, ax=axes[1, 1], cbar=False, alpha=0.1)\n",
    "axes[1, 1].scatter(*cls_tica.cluster_centers.T, s=15, c='C1')\n",
    "axes[1, 1].set_xlabel('IC 1')\n",
    "axes[1, 1].set_ylabel('IC 2')\n",
    "ax_its = plot_implied_timescales(its_pca, ax=axes[0, 2], n_its=4)\n",
    "ax_its.set_yscale('log')\n",
    "ax_its.set_xlabel('lagtime (ps)')\n",
    "ax_its = plot_implied_timescales(its_tica, ax=axes[1, 2], n_its=4)\n",
    "ax_its.set_yscale('log')\n",
    "ax_its.set_xlabel('lagtime (ps)')\n",
    "axes[0, 2].set_ylim(1, 2000)\n",
    "axes[1, 2].set_ylim(1, 2000)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the fact that PCA yields a projection with some defined basins,\n",
    "the ITS plot shows that only one \"slow\" process is resolved which is more than one order of magnitude too fast.\n",
    "\n",
    "TICA does find three slow processes which agree (in terms of the implied timescales) with the backbone torsions example above.\n",
    "\n",
    "We conclude that this PCA projection is not suitable to resolve the slow dynamics of alanine dipeptide and we will continue to estimate/validate the TICA-based projection.\n",
    "\n",
    "#### Exercise 2\n",
    "\n",
    "Estimate a Bayesian MSM at lag time $10$ ps and perform/show a CK test for four metastable states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "counts_estimator = TransitionCountEstimator(lagtime=10, count_mode=\"effective\")\n",
    "counts = counts_estimator.fit_fetch(dtrajs_tica).submodel_largest()\n",
    "bayesian_msm = # FIXME\n",
    "pyemma.plots. #FIXME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "###### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "counts_estimator = TransitionCountEstimator(lagtime=10, count_mode=\"effective\")\n",
    "counts = counts_estimator.fit_fetch(dtrajs_tica).submodel_largest()\n",
    "\n",
    "test_model = BayesianMSM(n_samples=50).fit_fetch(counts)\n",
    "\n",
    "models = []\n",
    "for i in tqdm(range(1, 10)):\n",
    "    counts = TransitionCountEstimator(lagtime=i * test_model.lagtime, count_mode=\"effective\")\\\n",
    "        .fit_fetch(dtrajs_tica).submodel_largest()\n",
    "    models.append(BayesianMSM(n_samples=50).fit_fetch(counts))\n",
    "\n",
    "ck_test = test_model.ck_test(models, n_metastable_sets=4)\n",
    "plot_ck_test(ck_test, xlabel='lagtime (ps)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again see a good agreement between model prediction and re-estimation.\n",
    "\n",
    "## Wrapping up\n",
    "In this notebook, we have learned how to estimate a regular or Bayesian MSM from discretized molecular simulation data with `deeptime` and `pyemma`, also how to perform basic model validation.\n",
    "\n",
    "In detail, we have selected a suitable lag time by\n",
    "- computing timescales from MSMs and Bayesian MSMs\n",
    "- `pyemma.plots.plot_implied_timescales()` to visualize the convergence of the implied timescales.\n",
    "\n",
    "We then have used\n",
    "- `dt.markov.TransitionCountEstimator()` to estimate transition counts\n",
    "- `dt.markov.msm.MaximumLikelihoodMSM()` to estimate a regular MSM,\n",
    "- `dt.markov.msm.BayesianMSM()` to estimate a Bayesian MSM,\n",
    "- the `timescales()` method of an estimated MSM object to access its implied timescales,\n",
    "- the `chapman_kolmogorov_validator()` method of an estimated MSM estiamator to perform a Chapman-Kolmogorow test, and\n",
    "- `pyemma.plots.plot_cktest()` to visualize the latter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
